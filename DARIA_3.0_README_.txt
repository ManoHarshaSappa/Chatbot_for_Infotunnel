
DARIA 3.0 (InfoTunnel)
=======================

Introduction
------------
DARIA 3.0 is a domain-specific question-answering (QA) system designed to provide efficient and accurate responses based on the InfoTunnel knowledge base. 
The system leverages state-of-the-art natural language processing (NLP) models like Meta LLaMA and Microsoft Phi2, with the ability to process both text and 
voice inputs. The core functionality includes knowledge retrieval using FAISS for embedding-based search, and response generation via Hugging Face models. 
The system is designed to answer questions related to specific domains, such as Acoustic Emission (AE) testing in tunnels and steel structures.

Solution Overview
-----------------
Main Features:
- Voice Input Integration: Uses OpenAI's Whisper model for speech-to-text conversion, enabling voice input.
- Knowledge Base: 
  - Processes data from JSON files containing domain-specific information.
  - Converts text data into a searchable knowledge base using FAISS and Hugging Face Embeddings.
- Model Fine-Tuning: 
  - LLaMA and Phi2 models are fine-tuned on domain-specific data to provide accurate answers.
  - Fine-tuning Process: The `F_tune.py` script is used to fine-tune the models on domain-specific data, ensuring that the models are adapted to handle 
    the unique vocabulary and queries relevant to the InfoTunnel domain.
- Interactive Interface: The frontend is built using Streamlit, providing a user-friendly interface for interacting with the system.

Input/Output Example:
- Input (via text or voice):
  - Text: "What are the advantages of Dye Penetrant Testing (DPT)?"
  - Voice: User speaks, and the system transcribes the input via Whisper.
- Output:
  - Response: A concise and domain-specific response generated by the fine-tuned models.

System Requirements
-------------------
- Python 3.x
- Required Python libraries: streamlit, langchain, FAISS, transformers, sounddevice, numpy, huggingface_hub, openai-whisper, etc.

How to Set Up and Run the System
--------------------------------
1. Install Dependencies:
   Install the required libraries using the command:
   ```
   pip install -r requirements.txt
   ```

2. Set Up Environment Variables:
   Ensure you set your Hugging Face API Token as an environment variable:
   ```
   export HUGGINGFACEHUB_API_TOKEN='your-api-token'
   ```

3. Download the Data:
   Place the scraped JSON data (e.g., `scraped_content.json`) in a directory specified by the `json_path` variable in the code.

4. Fine-Tuning the Model:
   Run the `F_tune.py` script to fine-tune the model on the domain-specific dataset. This script will fine-tune LLaMA and Phi2 models on the data you provide 
   (e.g., scraped or fine-tuned dataset).
   ```
   python F_tune.py
   ```
   After running the script, the fine-tuned model will be saved and can be used in the subsequent steps.

5. Run the Application:
   To run the app, use:
   ```
   streamlit run app.py
   ```

Running the Model
-----------------
- Voice Input:
  Click the "Record Voice" button to record a voice query. The system will transcribe and process the voice input using Whisper.

- Text Input:
  Type a query in the input box to retrieve answers. The system uses the knowledge base and fine-tuned models to generate a response.

- Model Evaluation:
  The model evaluation page allows you to compare the performance of the Microsoft Phi2 and Meta LLaMA models across different technical domains using 
  evaluation criteria such as accuracy, relevance, clarity, and conciseness.

Datasets
--------
The datasets used in this project were scraped from the InfoTunnel website, specifically for the domain of Acoustic Emission (AE) testing in tunnels and 
steel structures. The data is provided in JSON format.

**Dataset Links:**
- Scraped Content JSON
- Fine-Tuned Dataset JSON

Additional Notes
----------------
- The project integrates multiple models, including LLaMA for general question-answering and Phi2 for more specific tasks.
- The FAISS library is used for efficient knowledge retrieval, ensuring that the system can quickly fetch relevant information based on the userâ€™s query.
- The Streamlit framework is utilized for providing an interactive web interface to interact with the system.

Acknowledgments
---------------
We would like to thank:
- Dr. Lindi Liao for her guidance and support throughout this project.
- George Mason University for providing resources and the platform for this project.
- GTAs for their assistance in technical aspects and troubleshooting.
